#!/usr/bin/env python
# -*- coding: utf-8 -*-
import copy
import time
import argparse

import cv2 as cv
import numpy as np
import onnxruntime

#  CityScapes:19, CamVid:11 classes
def run_inference(onnx_session, image):
    input_name = onnx_session.get_inputs()[0].name
    input_size = onnx_session.get_inputs()[0].shape
    input_width = input_size[3]
    input_height = input_size[2]

    # Pre-process
    input_image = cv.resize(image, dsize=(input_width, input_height))
    input_image = cv.cvtColor(input_image, cv.COLOR_BGR2RGB)
    mean = [0.485, 0.456, 0.406]
    std = [0.229, 0.224, 0.225]
    input_image = (input_image / 255.0 - mean) / std
    input_image = input_image.transpose(2, 0, 1).astype('float32')
    input_image = np.expand_dims(input_image, axis=0)

    # Inference
    result = onnx_session.run(None, {input_name: input_image})
    segmentation_map = np.squeeze(result[0])  # shape: (H, W)

    return segmentation_map


def main():
    # Hardcoded path to video file
    video_path = "/home/deen/ros2_ws/src/automama/automama/perception/killo_road.mp4"

    model_path = "/home/deen/ros2_ws/src/automama/automama/perception/PID net models/onnx/pidnet_L_cityscapes_480x640.onnx"

    # Open video file
    cap = cv.VideoCapture(video_path)
    if not cap.isOpened():
        print(f"Failed to open video: {video_path}")
        return

    # Load ONNX model
    onnx_session = onnxruntime.InferenceSession(
        model_path,
        providers=[
            # 'CUDAExecutionProvider',
            'CPUExecutionProvider',
        ]
    )

    print("Starting inference on video... Press ESC to exit.")
    while True:
        start_time = time.time()

        ret, frame = cap.read()
        if not ret:
            print("End of video.")
            break

        debug_image = copy.deepcopy(frame)

        # Run inference
        segmentation_map = run_inference(onnx_session, frame)
        print(np.max(segmentation_map))
        elapsed_time = time.time() - start_time

        # Draw results
        debug_image = draw_debug(debug_image, elapsed_time, segmentation_map, class_num=19)

        # Show
        cv.imshow('PIDNet Segmentation', debug_image)

        key = cv.waitKey(1)
        if key == 27:  # ESC
            break

    cap.release()
    cv.destroyAllWindows()


def get_color_map_list(num_classes, custom_color=None):
    num_classes += 1
    color_map = num_classes * [0, 0, 0]
    for i in range(num_classes):
        j = 0
        lab = i
        while lab:
            color_map[i * 3 + 2] |= (((lab >> 0) & 1) << (7 - j))
            color_map[i * 3 + 1] |= (((lab >> 1) & 1) << (7 - j))
            color_map[i * 3 + 0] |= (((lab >> 2) & 1) << (7 - j))
            j += 1
            lab >>= 3
    color_map = color_map[3:]
    if custom_color:
        color_map[:len(custom_color)] = custom_color
    return color_map


def draw_debug(image, elapsed_time, segmentation_map, class_num=2):
    color_map = get_color_map_list(class_num)

    for index in range(class_num):
        mask = np.where(segmentation_map == index, 0, 1)

        bg_image = np.zeros_like(image)
        bg_image[:] = (
            color_map[index * 3 + 0],
            color_map[index * 3 + 1],
            color_map[index * 3 + 2]
        )

        mask = np.stack((mask,) * 3, axis=-1).astype('uint8')
        mask = cv.resize(mask, (image.shape[1], image.shape[0]))
        mask_image = np.where(mask, image, bg_image)
        image = cv.addWeighted(image, 0.5, mask_image, 0.5, 1.0)

    cv.putText(image,
               "Elapsed Time : {:.1f}ms".format(elapsed_time * 1000),
               (10, 30),
               cv.FONT_HERSHEY_SIMPLEX, 0.7, (0, 255, 0), 2, cv.LINE_AA)
    return image


if __name__ == '__main__':
    main()
